{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93166c3",
   "metadata": {},
   "source": [
    "# Chapter 01 한눈에 보는 머신러닝\n",
    "## 왜 머신러닝을 사용하는가?\n",
    "\n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제\n",
    "    - 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 할 수 있다.\n",
    "- 전동적인 방식으로는 해결 방법이 없는 복잡한 문제\n",
    "    - 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있다.\n",
    "- 유동적인 환경\n",
    "    - 머신러닝 시스템은 새로운 데이터에 적응할 수 있다.\n",
    "- 복잡한 문제와 대량의 데이터에서 통찰 얻기\n",
    "\n",
    "\n",
    "## 머신러닝 시스템의 종류\n",
    "\n",
    "- 사람의 감독하에 훈련하는 것인지 그렇지 않은 것인지(지도, 비지도, 준지도, 강화 학습)\n",
    "- 실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습과 배치 학습)\n",
    "- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지(사례 기반 학습과 모델 기반 학습)\n",
    "\n",
    "### 지도 학습과 비지도 학습\n",
    "\n",
    "- 머신러닝 시스템을 '학습하는 동안의 감독 형태나 정보량'에 따라 분류할 수 있다.\n",
    "- 지도 학습, 비지도 학습, 준지도 학습, 강화 학습 등 네 가지 주요 범주가 있다.\n",
    "\n",
    "#### 지도 학습(supervised learning)\n",
    "\n",
    "- 지도 학습에는 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함된다.\n",
    "- **분류**(classification)와 **회귀**(regression)으로 나뉜다.\n",
    "\n",
    "<img src=\"./images/1-5.png\" style = \"float: center; width: 600px;\">\n",
    "<img src=\"./images/1-6.png\" style = \"float: center; width: 600px;\">\n",
    "    \n",
    "\n",
    "\n",
    "- 다음은 일반적은 지도 학습 알고리즘이다.\n",
    "    - k-최근접 이웃(k-nearest neighbors)\n",
    "    - 선형 회귀(linear regression)\n",
    "    - 로지스틱 회귀(logistic regression)\n",
    "    - 서포트 벡터 머신(support vector machine)\n",
    "    - 결정 트리(decision tree)와 랜덤 포레스트(random forest)\n",
    "    - 신경망(neural networks)\n",
    "\n",
    "\n",
    "#### 비지도 학습(unsupervised learning)\n",
    "\n",
    "- 비지도 학습은 훈련 데이터에 레이블이 없다.\n",
    "- 즉, 시스템의 아무런 도운 없이 학습해야 한다.\n",
    "\n",
    "\n",
    "- 다음은 일반적인 비지도 학습 알고리즘 이다.\n",
    "    - 군집(clustering)\n",
    "        - k-평균(k-means)\n",
    "        - DBSCAN\n",
    "        - 계층 군집 분석(hierarchical cluster analysis, HCA)\n",
    "        - 이상치 탐지(outlier detection)와 특이치 탐치(novelty detection)\n",
    "        - 원-클래스(one-class SVM)\n",
    "        - 아이솔레이션 포레스트(isolation forest)\n",
    "    - 시각화(visualization)와 차원 축소(dimensionality reduction)\n",
    "        - 주성분 분석(principal component analysis, PCA)\n",
    "        - 커널(kernel) PCA\n",
    "        - 지역적 선형 임베딩(locally-linear embedding, LLE)\n",
    "        - t-SNE(t-distributed stochastic neighbor embedding)\n",
    "    - 연관 규칙 학습(association rule learning)\n",
    "        - 어프라이어리(Apriori)\n",
    "        - 이클렛(Eclat)\n",
    "\n",
    "<img src=\"./images/1-8.png\" style = \"float: center; width: 600px;\">\n",
    "\n",
    "\n",
    "#### 준지도 학습(semisupervised learning)\n",
    "\n",
    "- 데이터에 레이블을 다는 것은 일반적으로 시간과 비용이 많이 들기 때문에 레이블이 없는 샘플이 많다.\n",
    "- 준지도 학습은 일부만 레이블이 있는 데이터를 다룬다.\n",
    "- 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.\n",
    "\n",
    "\n",
    "#### 강화 학습\n",
    "\n",
    "- 강화 학습에서는 학습하는 시스템을 **에이전트**라고 부르며 환경(environment)을 관찰해서 행동(action)을 실행하고 그 결과 **보상**(reward) 또는 **벌점**(penalty)을 받는다.\n",
    "- 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책**(policy)이라고 부르는 최상의 전략을 스스로 학습한다.\n",
    "- 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의한다.\n",
    "\n",
    "<img src=\"./images/1-12.png\" style = \"float: center; width: 600px;\">\n",
    "\n",
    "\n",
    "\n",
    "### 배치 학습과 온라인 학습\n",
    "\n",
    "- 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부로 머신러닝 시스템을 분류\n",
    "\n",
    "\n",
    "#### 배치 학습(batch learning)\n",
    "\n",
    "- 배치 학습에서는 시스템이 점진적으로 학습할 수 없다.\n",
    "- 가용한 데이터를 모두 사용해 훈련시켜야 한다.\n",
    "- 일반적으로 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행된다.\n",
    "- 먼저 시스템을 훈련시키고 제품에 시스템을 적용하면 더 이상의 학습없이 실행된다.\n",
    "- 즉, 학습한 것을 단지 적용만 한다. 이를 오프라인 학습이라고 한다.\n",
    "- 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야 한다.\n",
    "\n",
    "\n",
    "#### 온라인 학습(online learning)\n",
    "\n",
    "- 온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 **미니배치**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다.\n",
    "- 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.\n",
    "\n",
    "\n",
    "### 사례 기반 학습과 모델 기반 학습\n",
    "\n",
    "- 머신러닝 시스템은 어떻게 **일반화**(generalize)되는가에 따라 분류할 수 있다.\n",
    "- 머신러닝 작업은 예측을 만드는 것인데, 이 말은 주어진 훈련 데이터로 학습하고 훈련 데이터에서는 본 적 없는 새로운 데이터에서 좋은 예측을 만들어야 한다는 뜻이다.\n",
    "- 훈련 데이터에서 높은 성능을 내는 것이 좋지만 그게 전부는 아니고, 새로운 샘플에 잘 작동하는 모델이 목표\n",
    "- 다음은 일반화를 위한 두 가지 접근법이다.\n",
    "\n",
    "\n",
    "#### 사례 기반 학습(instance-based learning)\n",
    "\n",
    "- 가장 단단한 형태의 학습은 단순히 기억하는 것이다.\n",
    "- 사례 기반 학습은 시스템이 훈련 샘플을 기억함으로써 학습한다.\n",
    "- 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화한다.\n",
    "\n",
    "<img src=\"./images/1-15.png\" style = \"float: center; width: 600px;\">\n",
    "\n",
    "\n",
    "#### 모델 기반 학습(model-based learning)\n",
    "\n",
    "- 모델 기반 학습은 샘플들의 모델을 만들어 예측에 사용하는 것이다.\n",
    "\n",
    "<img src=\"./images/1-16.png\" style = \"float: center; width: 600px;\">\n",
    "\n",
    "\n",
    "## 머신러닝의 주요 도전 과제\n",
    "\n",
    "#### 1. 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "- 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다.\n",
    "- 아주 간단한 문제에서조차도 수천 개의 데이터가 필요하고 이미지나 음성 인식 같은 복잡한 문제라면 수백만 개가 필요할지도 모른다.\n",
    "\n",
    "#### 2. 대표성 없는 훈련 데이터\n",
    "\n",
    "- 일반화가 잘되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다.\n",
    "- 샘플이 작으면 샘플링(sampling noise)이 생긴다. 즉, 우연에 의한 대표성 없는 데이터\n",
    "- 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있다. 이를 샘플링 편향(sampling bias)라고 한다.\n",
    "\n",
    "#### 3. 낮은 품질의 데이터\n",
    "\n",
    "- 훈련 데이터가 에러, 이상치(outlier), 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다.\n",
    "\n",
    "#### 4. 관련 없는 특성\n",
    "\n",
    "- 훈련 데이터에 관련 없는 특성이 적고 관련 있는 특성이 충분해야 시스템이 학습할 수 있다.\n",
    "\n",
    "#### 5. 훈련 데이터 과대적합(overfitting)\n",
    "\n",
    "- 훈련 데이터에 과도하게 일반화 된다면 새로운 데이터에 대해서 잘 예측할 수 없다.\n",
    "- 과대적합의 해결방법\n",
    "    - 파리미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화 시킨다.\n",
    "    - 훈련 데이터를 더 많이 모은다.\n",
    "    - 훈련 데이터의 잡음을 줄인다.\n",
    "\n",
    "#### 6. 훈련 데이터 과소적합(underfitting)\n",
    "\n",
    "- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다.\n",
    "- 과소적합의 해결방법\n",
    "    - 모델 파라미터가 더 많은 강력한 모델 선택\n",
    "    - 학습 알고리즘에 더 좋은 특성을 제공\n",
    "    - 모델의 제약을 줄이기\n",
    "\n",
    "\n",
    "### 테스트와 검증\n",
    "\n",
    "- 모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해 보는 것이다.\n",
    "- 더 나은 방법은 훈련 데이터를 훈련 세트와 테스트 세트 두 개로 나누는 것이다.\n",
    "- 훈련 세트를 사용해 모델을 훈련하고 테스트 세트를 사용해 모델을 테스트한다.\n",
    "- 훈련 오차가 낮지만 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과대적합되었다는 뜻이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
